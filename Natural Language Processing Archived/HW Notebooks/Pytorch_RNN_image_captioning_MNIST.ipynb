{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1626,"status":"ok","timestamp":1716545455773,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"2OoUWgrFi82h"},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716545461949,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"MN1Z7uGbxTdq","scrolled":true},"outputs":[],"source":["# %pip install torch torchvision pillow spacy numpy\n","# %pip install torchtext\n","# %pip install pycocotools"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716545461950,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"5EDyhvMIxybA"},"outputs":[],"source":["import os\n","import math\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","from torch.utils.data import DataLoader, Dataset, Subset\n","from torchvision.datasets import MNIST\n","\n","from tqdm import tqdm\n","\n","from PIL import Image\n","import spacy"]},{"cell_type":"markdown","metadata":{"id":"pzeLAtu9zQFv"},"source":["## Building the tokenizer and vocabulary"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1716545461950,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"I2kg8R_nhN1A"},"outputs":[],"source":["spacy_eng = spacy.load(\"en_core_web_sm\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716545461950,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"y-3CxVtzxcd6"},"outputs":[],"source":["def word_tokenize(text):\n","    return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716545461950,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"mFOLfFKebpCf"},"outputs":[],"source":["numerical_to_word_numbers = {\n","    0: \"Zero\",\n","    1: \"One\",\n","    2: \"Two\",\n","    3: \"Three\",\n","    4: \"Four\",\n","    5: \"Five\",\n","    6: \"Six\",\n","    7: \"Seven\",\n","    8: \"Eight\",\n","    9: \"Nine\"\n","}\n","\n","possible_caption_templates = [\n","    \"This is an image of the number <number>\",\n","    \"We can see the number <number> in this image\",\n","    \"Number <number> is displayed here\",\n","    \"In this image, the number <number> is shown\",\n","    \"Here, you can see the number <number>\",\n","    \"The image features the number <number>\",\n","    \"Displayed in the image is the number <number>\"\n","]"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716545461950,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"_JQ8Ow_t7B7P","outputId":"3d426c95-3f30-4ef2-e308-7555acfae567"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 17/17 [00:00<00:00, 257412.16it/s]\n"]}],"source":["# Define the vocabulary and tokenizer\n","word_to_index = {'<PAD>':0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n","\n","for text in tqdm(possible_caption_templates+list(numerical_to_word_numbers.values())):\n","    tokens = word_tokenize(text.lower())\n","    for token in tokens:\n","        if token not in word_to_index:\n","            idx = len(word_to_index)\n","            word_to_index[token] = idx\n","\n","index_to_word = {it: k for k, it in word_to_index.items()}"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1716545461950,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"Mbv23I3-xUee","outputId":"b407a877-60dd-42e0-a8c4-3343ff617721"},"outputs":[{"data":{"text/plain":["['<', 'sos', '>', 'testing', 'tokenization', 'breakdown', '<', 'eos', '>']"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["word_tokenize('<SOS> Testing tokenization breakdown <EOS>')  # We will manually add tokens for <EOS> and <SOS> etc after tokenization to avoid them breaking up."]},{"cell_type":"markdown","metadata":{"id":"xKBTTh7IrvTK"},"source":["## Defining the dataset"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1716545463624,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"0hs0N5Ouay0H"},"outputs":[],"source":["def get_random_caption(num):\n","\n","    template_idx = random.randint(0, len(possible_caption_templates)-1)\n","    template = possible_caption_templates[template_idx]\n","\n","    caption = template.replace('<number>', numerical_to_word_numbers[num])\n","\n","    return caption\n","\n","\n","def convert_sentence_to_idxs(sentence):\n","\n","    words = word_tokenize(sentence)\n","    idxs = [word_to_index[word] for word in words]\n","\n","    return idxs\n","\n","\n","def convert_idxs_to_sentence(idxs):\n","\n","    words = [index_to_word[idx] for idx in idxs]\n","    return ' '.join(words)\n","\n","\n","class MNISTCaptionsDataset(Dataset):\n","\n","    def __init__(self, *args, **kwargs):\n","\n","        self.mnist = MNIST(*args, **kwargs)\n","        self.max_seq_len = 50\n","\n","    def __len__(self):\n","        return len(self.mnist)\n","\n","    def __getitem__(self, idx):\n","\n","        img, label = self.mnist[idx]\n","        caption = get_random_caption(label)\n","\n","        caption_idxs = convert_sentence_to_idxs(caption.lower().strip())\n","        if len(caption_idxs) > self.max_seq_len - 2:  # 2 for SOS and EOS\n","            caption_idxs = caption_idxs[:self.max_seq_len-2]\n","\n","        padding_len = self.max_seq_len - len(caption_idxs) - 2  # need to pad to make it to seq_len. All captions Need to be of same length so they can be stacked\n","\n","        caption_numeric = (\n","            [word_to_index['<SOS>']]+\n","            caption_idxs+\n","            [word_to_index['<EOS>']]+\n","            [word_to_index['<PAD>']]*padding_len\n","        )\n","\n","        caption_numeric = torch.Tensor(caption_numeric)\n","\n","        return img, caption_numeric, caption\n","\n"]},{"cell_type":"markdown","metadata":{"id":"i79_gIk-1zut"},"source":["## Defining the Model"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":823,"status":"ok","timestamp":1716545762575,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"D59I4JSZe46D"},"outputs":[],"source":["class EncoderCNN(nn.Module):\n","    def __init__(self, embed_size):\n","        super(EncoderCNN, self).__init__()\n","\n","        # Normally, it would be a good idea to use a pre-trained model as a backbone for feature extraction\n","        # However, most pretrained models expect RGB images and ones that are bigger in size than 28x28\n","        # For this reason, you have been provided with commented code to see how we could have used\n","        # resnet backbone in case of some other dataset but we will use our own custom CNN\n","        # model for feature extraction.\n","        # We could have converted MNIST images to RGB and upscaled their size but that would have\n","        # drastically increased the training time.\n","\n","        # self.resnet = models.resnet50(pretrained=True).requires_grad_(False)  # resnet embedding backbone\n","        # self.resnet.fc = nn.Linear(self.resnet.fc.in_features, embed_size)\n","        # self.relu = nn.ReLU()\n","        # self.times = []\n","\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n","        self.fc2 = nn.Linear(128, embed_size)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","\n","        x = self.pool(self.relu(self.conv1(x)))\n","        x = self.pool(self.relu(self.conv2(x)))\n","        x = x.view(-1, 64 * 7 * 7)\n","        x = self.relu(self.fc1(x))\n","        embedding = self.fc2(x)\n","        embedding = self.relu(embedding)\n","\n","        return embedding\n","\n","    # def forward(self, images):\n","\n","    #     features = self.resnet(images)\n","    #     return self.relu(features)\n","\n","\n","class DecoderRNN(nn.Module):\n","    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n","        super(DecoderRNN, self).__init__()\n","        self.embed = nn.Embedding(vocab_size, embed_size)\n","\n","        self.rnn = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n","\n","        # NOTE: We can replace the LSTM architecture by RNN or GRU by replacing the above line by one of the following\n","\n","        # self.rnn = nn.RNN(embed_size, hidden_size, num_layers, batch_first=True)\n","        # self.rnn = nn.GRU(embed_size, hidden_size, num_layers, batch_first=True)\n","\n","        self.linear = nn.Sequential(\n","            nn.Linear(hidden_size, 1024),\n","            nn.Linear(1024, vocab_size)\n","        )\n","\n","    def forward(self, features, captions):\n","\n","        embeddings = self.embed(captions)\n","        embeddings = torch.cat((features.unsqueeze(1), embeddings), dim=-2)\n","        hiddens, _ = self.rnn(embeddings)\n","        outputs = self.linear(hiddens)\n","        return outputs\n","\n","\n","class ImageCaptioner(nn.Module):\n","\n","    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n","        super(ImageCaptioner, self).__init__()\n","        self.encoder = EncoderCNN(embed_size)\n","        self.decoder = DecoderRNN(embed_size, hidden_size, vocab_size, num_layers)\n","\n","    def forward(self, images, captions):\n","        features = self.encoder(images)\n","        outputs = self.decoder(features, captions)\n","        return outputs\n","\n","    def caption_image(self, image, max_length=50):\n","\n","        result_caption = []\n","\n","        with torch.no_grad():\n","            x = self.encoder(image)\n","            states = None\n","\n","            for _ in range(max_length):\n","\n","                hiddens, states = self.decoder.rnn(x, states)\n","                output = self.decoder.linear(hiddens.squeeze(0))\n","\n","                predicted = output.argmax(0)\n","                pred_token = index_to_word[predicted.item()]\n","                result_caption.append(pred_token)\n","                x = self.decoder.embed(predicted).unsqueeze(0)\n","\n","                if pred_token == \"<EOS>\":\n","                    break\n","\n","        return result_caption"]},{"cell_type":"markdown","metadata":{},"source":["## Initializing the model and dataset"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1716545763360,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"3OVeS6Txbbzc"},"outputs":[],"source":["train_transforms = transforms.Compose(\n","        [\n","            # If we want to upscale MNIST images and convert to RGB\n","            # transforms.Grayscale(num_output_channels=3),\n","            # transforms.Resize((299, 299)),\n","\n","            transforms.ToTensor(),\n","        ]\n","    )\n","\n","batch_size = 128\n","total_dataset = MNISTCaptionsDataset(root='./datasets', train=False, download=True, transform=train_transforms)\n","\n","train_dataset = Subset(total_dataset, range(len(total_dataset) - 100))\n","test_dataset = Subset(total_dataset, range(len(total_dataset) - 100, len(total_dataset)))\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","clear_output()"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1716545763361,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"rlsyakwKrQ2Z","outputId":"eeb1b8fb-a584-48dd-b5b1-48bafa863981"},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":829,"status":"ok","timestamp":1716545773337,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"5YB-RYSH2DmL"},"outputs":[],"source":["embed_size = 128\n","hidden_size = 128\n","vocab_size = len(word_to_index)\n","num_decoder_layers = 1\n","learning_rate = 5e-5\n","num_epochs = 150"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1716545774472,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"v7-7f4gmhr5u"},"outputs":[],"source":["# initialize model, loss etc\n","model = ImageCaptioner(embed_size, hidden_size, vocab_size, num_decoder_layers).to(device)\n","criterion = nn.CrossEntropyLoss(ignore_index=word_to_index['<PAD>'])  # ignore pad token loss calculations\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"Db6Iq3hU3GMk"},"source":["## Pre-training Testing"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1716545775163,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"QtS8hnpH3K3D"},"outputs":[],"source":["test_samples = [test_dataset[i] for i in range(10, 13)]\n","test_imgs, test_caption_tensors, test_captions = list(zip(*test_samples))\n","\n","test_imgs = torch.stack(test_imgs, 0).to(device)"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":45},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1716545776984,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"Ptk58laBofd_","outputId":"79ed5fb3-5f70-4e16-f06c-e12c603b0155"},"outputs":[{"data":{"image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABUABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+lRGd1RFLMxwFAySa1E8Oar/a9lplzZT2dzeOiRC5hdM7iADjGSOewNQa1pNzoWtXmlXZjNxaStFIY23KSPQ+lUa9j+D/AIfh0/RNZ8a6mfsS2sW2wvpYzKqZysjiMcsRwAemWNUNQ+JmmaMFPhuO/wBT1VEZBrWtyGWSIt1MMZJCZ9fzBry6aWS4mkmmdpJZGLu7HJYk5JJrT8MaK3iLxNp+kLIIxczBGkIyEXqzfgATXq1tqMupWfjXUY4TZ+EItHfTdMV8qjlT+6255ZidzH/eOa8ToqezvbrTruO7srma2uYzlJoJCjrxjhhyODVnUNd1jV4ootS1W+vY4c+WlzcPIEz1wGJx0FZ9FFeteB/hjo/9gr4p8d6gun6UwEltAZgrToOpOPmweMBfmP5Z6fw94v0jxte6h4StPCdlD4Ut7OWYOsX72PYuFk6gbiTx3569a+fq7z4Y+GLLVrzUte1hDJo2gQC7uoVwWmPzFUweoOxs/THeqHiXxFr3xN8VxuttJNM37qzsoFyI0znAH8yf5Curu7jTvhl4G1HQYLuG68W6soivXtyCLKI9Yt/QnqCB3PsM+T113gbx0/g19Sgm02HU9N1OEQ3dpI5TeBnGGAOPvMOnetbVvizdSWr2fhnQ9N8N2zqVZ7OMGcg5yPMwOOewB9688JLMWYkknJJ70lFFddoXgaTUfC+oeJNUv10rSrdCIJpIi5upu0aDIzyCCRnHp1xyNFdp8P8AwI/iu8kvtQl+xeHbHL31652gADO1SeN3T6A59AbPxH8fr4nmh0jR4/svhrT8JaW6rt34GN7D8TgenvmuCrqvAfhCPxdrE8d3qEen6bZQm5vLlyPkjBA4yepz16D9DsePvHdrqNlD4W8Lwmy8M2eAqqSGumBzvf1GecHvz6Y89ooooor/2Q==","image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAABUCAAAAAC0bQhJAAACt0lEQVR4Ae2VT0hUURTGT1OTjqOGkGGNWRqlGUJhhpFTWhiS1kKmQmtji9oUUqssXGhChruIgnJh0V8DCVSkP0Y6WFogSak1M2rFJIOZmk6aNd+190bvvDvP95Ytit7mfOf7nfPevee9O0P0d1yJLzoTiQzqxRqiZcfRuilDTYgO1g092UO0zjW+Vw2NLexzm+MKrepiN9SMill/Ei2JLHGz7jg1zJlgxWSp6mbs4Qo1i5+cOpNxzsF8dYfmrZNokn30sWnnEXWXnMdOM/a6fIsWomwnmyo1i0i5ualiuTPE+10bnkizOWmlyBSdOlm/uIhdXqg4irL0DSZTwogrVLGUwa+Jt/fQmDdkgQjndFgXiyCKdg+YRDi32sKUJi/RtqgZkXFdOhxDlP+eVXJDjPZm2lDuYhc3iibX9qmWQcayg+bD2T8aYyq72S7NN0eRBb8gXXcsGlvf91JG0nV+HjzdPAr8PJWV1Yi7amgdllp6jkq2DVDB9G/y/Q7Lrg2XguGxH4DvTZz8nRjaZp+5iFcszTGymse1/jQznbuzMbwXvgvc2g9YuZZixD3AxXOrB01GnkixELgfOK63ge0Cyx3Dg7U83z2K/mU8IQp9jv7AUc704kOSwqgKnxJ4mjmNAf9euTGD9jkZVub1XQ08wG8yDhOfwXOAtxAFhkC0IzI1J63jeKcC/eodxk82dEgvcqg2VoX8u5Rnjqfi9niVoaAXeFURFcKN/5Eo5SvL1ZtDciPGtQYp11uqMbpTpzHMDuTpMNM1wKN1AOX6MomV6DRavwD5OmzrCFAU9LMqFE4A1TqvPK2eoUb45IQuMtexmeuiIWhTH6DHzNLhcgi1ogy/BTToPC/8JtC+WaxWtFnqcwdOoeLLyvoWaF0d7PHM+Aho0v7fJDorrWU9r1THPN25qCv/fP4bDzAbicjEkfIAAAAASUVORK5CYII=","text/plain":["<PIL.Image.Image image mode=L size=28x84>"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["transforms.functional.to_pil_image(test_imgs.reshape([1, 1, -1, 28])[0])"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"data":{"text/plain":["('We can see the number Eight in this image',\n"," 'Here, you can see the number Zero',\n"," 'The image features the number One')"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["test_captions"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1716545776984,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"xiAYu3QXtHki","outputId":"e758c0c5-aaf0-490b-ff5e-a7f1e3f12edb"},"outputs":[{"name":"stdout","output_type":"stream","text":["is , two < < , < , < < , < , < < , < , < < , < , < < , < , < < , < , < < , < , < < , < , < < , < , < <\n","--------------------\n","is , two < < , < , < < , < , < < , < , < < , < , < < , < , < < , < , < < , < , < < , < , < < , < , < <\n","--------------------\n","is , two < < , < , < < , < , < < , < , < < , < , < < , < , < < , < , < < , < , < < , < , < < , < , < <\n"]}],"source":["# Predicted captions\n","\n","model.eval()\n","captions = []\n","\n","for img in test_imgs:\n","    with torch.no_grad():\n","        caption = model.caption_image(img.unsqueeze(0))\n","        caption = ' '.join(caption)\n","        captions.append(caption)\n","\n","print(('\\n'+'-'*20+'\\n').join(captions))"]},{"cell_type":"markdown","metadata":{"id":"oOQLLt_F3iIs"},"source":["## Training the model"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpeCGaogiE0Q","outputId":"4d1337ee-3a83-46fb-f75b-110d43a3d286"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> the number number <EOS>\n","--------------------\n","<SOS> the number number <EOS>\n","--------------------\n","<SOS> the number number <EOS>\n","\n","Epoch: 1/150 Training loss:  2.89863657951355\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 2/150 Training loss:  1.9204957485198975\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 3/150 Training loss:  1.1567866802215576\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 4/150 Training loss:  0.7788854837417603\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 5/150 Training loss:  0.6105071306228638\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 6/150 Training loss:  0.5163626074790955\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 7/150 Training loss:  0.5018609166145325\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 8/150 Training loss:  0.49324753880500793\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 9/150 Training loss:  0.4742995798587799\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 10/150 Training loss:  0.4775215685367584\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> here , you can see the number one <EOS>\n","--------------------\n","<SOS> here , you can see the number one <EOS>\n","--------------------\n","<SOS> here , you can see the number one <EOS>\n","\n","Epoch: 11/150 Training loss:  0.44236162304878235\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 12/150 Training loss:  0.478717565536499\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 13/150 Training loss:  0.44155240058898926\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 14/150 Training loss:  0.44935035705566406\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 15/150 Training loss:  0.45086878538131714\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 16/150 Training loss:  0.4512055516242981\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 17/150 Training loss:  0.458158403635025\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 18/150 Training loss:  0.4479886591434479\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 19/150 Training loss:  0.43479540944099426\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 20/150 Training loss:  0.43861761689186096\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> this is an image of the number eight <EOS>\n","--------------------\n","<SOS> this is an image of the number eight <EOS>\n","--------------------\n","<SOS> this is an image of the number eight <EOS>\n","\n","Epoch: 21/150 Training loss:  0.4308432936668396\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 22/150 Training loss:  0.46011602878570557\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 23/150 Training loss:  0.44080427289009094\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 24/150 Training loss:  0.4297908842563629\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 25/150 Training loss:  0.42865651845932007\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 26/150 Training loss:  0.4409169554710388\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 27/150 Training loss:  0.44410741329193115\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 28/150 Training loss:  0.4581775665283203\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 29/150 Training loss:  0.4505087435245514\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 30/150 Training loss:  0.4576365649700165\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> displayed in the image is the number one <EOS>\n","--------------------\n","<SOS> displayed in the image is the number one <EOS>\n","--------------------\n","<SOS> displayed in the image is the number one <EOS>\n","\n","Epoch: 31/150 Training loss:  0.4379013776779175\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 32/150 Training loss:  0.4362761676311493\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 33/150 Training loss:  0.44048166275024414\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 34/150 Training loss:  0.4473690092563629\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 35/150 Training loss:  0.4619070887565613\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 36/150 Training loss:  0.44537022709846497\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 37/150 Training loss:  0.4440281391143799\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 38/150 Training loss:  0.4559940993785858\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 39/150 Training loss:  0.43382129073143005\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 40/150 Training loss:  0.4377303123474121\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> displayed in the image is the number seven <EOS>\n","--------------------\n","<SOS> displayed in the image is the number seven <EOS>\n","--------------------\n","<SOS> displayed in the image is the number seven <EOS>\n","\n","Epoch: 41/150 Training loss:  0.43770846724510193\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 42/150 Training loss:  0.44368213415145874\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 43/150 Training loss:  0.44609591364860535\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 44/150 Training loss:  0.4600406289100647\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 45/150 Training loss:  0.4536103308200836\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 46/150 Training loss:  0.4349174499511719\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 47/150 Training loss:  0.44483083486557007\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 48/150 Training loss:  0.43184202909469604\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 49/150 Training loss:  0.4318259060382843\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 50/150 Training loss:  0.4418804943561554\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> number one is displayed here <EOS>\n","--------------------\n","<SOS> in this image , the number zero is shown <EOS>\n","--------------------\n","<SOS> displayed in the image is the number one <EOS>\n","\n","Epoch: 51/150 Training loss:  0.3917907476425171\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 52/150 Training loss:  0.4103187322616577\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 53/150 Training loss:  0.409627765417099\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 54/150 Training loss:  0.3667134940624237\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 55/150 Training loss:  0.3680402636528015\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 56/150 Training loss:  0.33439722657203674\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 57/150 Training loss:  0.33292561769485474\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 58/150 Training loss:  0.34968888759613037\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 59/150 Training loss:  0.3167118430137634\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 60/150 Training loss:  0.36140328645706177\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> in this image , the number eight is shown <EOS>\n","--------------------\n","<SOS> in this image , the number zero is shown <EOS>\n","--------------------\n","<SOS> in this image , the number one is shown <EOS>\n","\n","Epoch: 61/150 Training loss:  0.3309166431427002\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 62/150 Training loss:  0.29720738530158997\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 63/150 Training loss:  0.33068037033081055\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 64/150 Training loss:  0.3123643100261688\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 65/150 Training loss:  0.29832303524017334\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 66/150 Training loss:  0.28441503643989563\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 67/150 Training loss:  0.266236275434494\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 68/150 Training loss:  0.28272348642349243\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 69/150 Training loss:  0.2769301235675812\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 70/150 Training loss:  0.2736806571483612\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> this is an image of the number eight <EOS>\n","--------------------\n","<SOS> number zero is displayed here <EOS>\n","--------------------\n","<SOS> the image features the number one <EOS>\n","\n","Epoch: 71/150 Training loss:  0.28407445549964905\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 72/150 Training loss:  0.28149107098579407\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 73/150 Training loss:  0.2625976502895355\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 74/150 Training loss:  0.2835143506526947\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 75/150 Training loss:  0.3006846010684967\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 76/150 Training loss:  0.2501884698867798\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 77/150 Training loss:  0.24891643226146698\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 78/150 Training loss:  0.3007879853248596\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 79/150 Training loss:  0.2514306306838989\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 80/150 Training loss:  0.23779433965682983\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> this is an image of the number five <EOS>\n","--------------------\n","<SOS> this is an image of the number zero <EOS>\n","--------------------\n","<SOS> displayed in the image is the number one <EOS>\n","\n","Epoch: 81/150 Training loss:  0.25031447410583496\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 82/150 Training loss:  0.2645524740219116\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 83/150 Training loss:  0.2560802400112152\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 84/150 Training loss:  0.25332537293434143\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 85/150 Training loss:  0.24141670763492584\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 86/150 Training loss:  0.22325782477855682\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 87/150 Training loss:  0.24176575243473053\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 88/150 Training loss:  0.22422342002391815\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 89/150 Training loss:  0.22287064790725708\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 90/150 Training loss:  0.21987150609493256\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> here , you can see the number eight <EOS>\n","--------------------\n","<SOS> in this image , the number zero is shown <EOS>\n","--------------------\n","<SOS> in this image , the number one is shown <EOS>\n","\n","Epoch: 91/150 Training loss:  0.20612163841724396\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 92/150 Training loss:  0.22726158797740936\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 93/150 Training loss:  0.22447027266025543\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 94/150 Training loss:  0.21328279376029968\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 95/150 Training loss:  0.23727869987487793\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 96/150 Training loss:  0.23101145029067993\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 97/150 Training loss:  0.205208420753479\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 98/150 Training loss:  0.23017442226409912\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 99/150 Training loss:  0.22167710959911346\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 100/150 Training loss:  0.24376338720321655\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> we can see the number eight in this image <EOS>\n","--------------------\n","<SOS> number zero is displayed here <EOS>\n","--------------------\n","<SOS> number one is displayed here <EOS>\n","\n","Epoch: 101/150 Training loss:  0.2090206742286682\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 102/150 Training loss:  0.2134617120027542\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 103/150 Training loss:  0.2159380167722702\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 104/150 Training loss:  0.23359283804893494\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 105/150 Training loss:  0.2209450751543045\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 106/150 Training loss:  0.2116609811782837\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 107/150 Training loss:  0.22925306856632233\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 108/150 Training loss:  0.213944673538208\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 109/150 Training loss:  0.2518846094608307\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 110/150 Training loss:  0.21509043872356415\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> we can see the number eight in this image <EOS>\n","--------------------\n","<SOS> displayed in the image is the number zero <EOS>\n","--------------------\n","<SOS> displayed in the image is the number one <EOS>\n","\n","Epoch: 111/150 Training loss:  0.2215007096529007\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 112/150 Training loss:  0.23511788249015808\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 113/150 Training loss:  0.20859329402446747\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 114/150 Training loss:  0.21057714521884918\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 115/150 Training loss:  0.21211935579776764\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 116/150 Training loss:  0.21969589591026306\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 117/150 Training loss:  0.2322322577238083\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 118/150 Training loss:  0.20147965848445892\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 119/150 Training loss:  0.2276296317577362\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 120/150 Training loss:  0.21380746364593506\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> here , you can see the number eight <EOS>\n","--------------------\n","<SOS> here , you can see the number zero <EOS>\n","--------------------\n","<SOS> here , you can see the number one <EOS>\n","\n","Epoch: 121/150 Training loss:  0.22483102977275848\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 122/150 Training loss:  0.1998809576034546\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 123/150 Training loss:  0.23405496776103973\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 124/150 Training loss:  0.22122256457805634\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 125/150 Training loss:  0.21595580875873566\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 126/150 Training loss:  0.20256349444389343\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 127/150 Training loss:  0.2305578887462616\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 128/150 Training loss:  0.2000114768743515\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 129/150 Training loss:  0.20392724871635437\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 130/150 Training loss:  0.20612281560897827\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> this is an image of the number eight <EOS>\n","--------------------\n","<SOS> this is an image of the number zero <EOS>\n","--------------------\n","<SOS> this is an image of the number one <EOS>\n","\n","Epoch: 131/150 Training loss:  0.20281684398651123\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 132/150 Training loss:  0.1959560066461563\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 133/150 Training loss:  0.20198504626750946\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 134/150 Training loss:  0.20598438382148743\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 135/150 Training loss:  0.21098563075065613\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 136/150 Training loss:  0.21709705889225006\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 137/150 Training loss:  0.21760845184326172\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 138/150 Training loss:  0.2111542522907257\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 139/150 Training loss:  0.20859837532043457\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 140/150 Training loss:  0.21456947922706604\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["<SOS> here , you can see the number eight <EOS>\n","--------------------\n","<SOS> here , you can see the number zero <EOS>\n","--------------------\n","<SOS> here , you can see the number one <EOS>\n","\n","Epoch: 141/150 Training loss:  0.20859718322753906\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 142/150 Training loss:  0.20569942891597748\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 143/150 Training loss:  0.2019965946674347\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 144/150 Training loss:  0.21619203686714172\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 145/150 Training loss:  0.20778173208236694\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 146/150 Training loss:  0.22036497294902802\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 147/150 Training loss:  0.20381954312324524\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 148/150 Training loss:  0.21809279918670654\n"]},{"name":"stderr","output_type":"stream","text":["                                               \r"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 149/150 Training loss:  0.20756754279136658\n"]},{"name":"stderr","output_type":"stream","text":["                                               "]},{"name":"stdout","output_type":"stream","text":["\n","Epoch: 150/150 Training loss:  0.20486894249916077\n"]},{"name":"stderr","output_type":"stream","text":["\r"]}],"source":["for epoch in range(num_epochs):\n","\n","    model.train()\n","\n","    for idx, (imgs, captions, _) in tqdm(\n","        enumerate(train_loader), total=len(train_loader), leave=False\n","    ):\n","        imgs = imgs.to(device)\n","        captions = captions.to(device).type(torch.long)\n","\n","        outputs = model(imgs, captions[:, :-1])\n","        loss = criterion(\n","            outputs.reshape(-1, outputs.shape[2]), captions.reshape(-1)\n","        )\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    \n","    if epoch % 10 == 0:\n","        with torch.no_grad():\n","\n","            model.eval()\n","            captions = []\n","\n","            for img in test_imgs:\n","                with torch.no_grad():\n","                    caption = model.caption_image(img.unsqueeze(0))\n","                    caption = ' '.join(caption)\n","                    captions.append(caption)\n","\n","            print(('\\n'+'-'*20+'\\n').join(captions))\n","\n","    print(f'\\nEpoch: {epoch+1}/{num_epochs}', \"Training loss: \", loss.item())"]},{"cell_type":"markdown","metadata":{},"source":["## Testing the results"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"8Tg5Dg9tMIpr"},"outputs":[{"data":{"image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcARgBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+nbG2b9p2Zxuxxn0reuvDH2HwVZeIbu8EcmoTvHZ2gjyZETh5GbI2gHAGAc+1c/RWifD+tDTn1A6RfixT79z9mfy1+rYwKzqK3PCfha+8Ya7HpdiUjypkmnkzshjHVmPp/UirfijTvCmmW8NvoOr3mqXqPi5uGiWO3YYP+rB+bgjqcg1zFFdNpPw88Xa5ZQ3mnaDdzW0xxHLgKre4LEce/SqXiHwprnhSeCDXNPks5J0LxBmVgwBweVJHXt15B6EVjVt+F/DN14p1NrSCe3tYYozNcXdy22KCMdWY9uoA9Saqa3ZWGn6pLbabqX9pWyYAufJMQY98KSeM9D3HpWfRXaaJ4Etrnw/Fr3iLX4NC024ZktS8DTS3BXqVQY+UdM5rK8YeF5fCWvtpzXUV5C0ST29zEMLNE4yrYycfTJ/GsCtHRNB1TxHqH2HSLKS7udhcomBhR1JJwAPqaozQvbzyQybd8bFG2sGGQcHBHB+oplFdV4d+HPinxTp0t/pWlySWsYysjkIJTnG1M/eP6cdazPEnhfWPCWpjTtatDbXLRiVV3qwZTkAgqSDyCPwrIrpPBnhC58Xas0QlW1062QzX99JwltEOSxJ74BwP6Amq3iq40G41yT/hG7GS002NRGnmys7ykdZDk8Z9B0rEqezs7nULyGzs4HnuJmCRxxjLMT2Arp/EvgWXw9Jp9lFfpqmr3KO81pYJ5og2kgqXUklhhsjaMY61yNaGhaTNr2v2Gk25xLeTpCGxnbuOCT7Ac/hXovxJ0vWHvbPwroXhnU49F0o+VAy2L5vJsAPMSF+YnGAfTnvVX4yBNN1Hw/4bRMf2PpUULscfM7DJPH0H5mvNK6zwT4i0Lww17qOoaMdT1VEX+zllwYIn5y7jqSOMf0OCOz+HninXdd8Yal4l8Q6xcNpGn2ck1/GxzC6MCqw7D8vJPAxzj1Oa818Sa2/iLX7vVHtoLbz2+WG3jCIigYAAHsBz3rKrt/hZ4stfCvi3Ooxh9M1CFrO7PdUbHzfgQM+2aq/EjwgfBXjC402Nt9nKouLR85zExOM+4II98Z71yVd74D0jwU2nT634s1WQtb3ASHSLcZlucAHkdSpJ28Y6HkcV3+r+INVt4LTUfFSz+HvDUQB0zQbHYktwEZdscnIYKVznoBjsSu7yPxl4v1Lxtr76pqTjIXy4IlAAijBJCj16nk8mufr2HwBolr4n+FepWDXMlhbWeoLd6tJHH5j3FuqEhUwCQQQTjB9fauP8UeNLTUtMXQdB0W10zQ4pBIoKB7iZgMB5HPOcdh6kZNcdXTeCfCU/irWFEgaLSLUiXUrwuEWCAH5juIIDYzge3oDW3488b2ut29p4X8PWEUeh6cfJtZSm+ecA9dxGQCedo6nGfQJ8WbYaZq2g6O5DXOnaJbW9w28MfM+YkHHpkAe2K8/r0TwL4h8faJpYsPDWjPcWt9MWDnTjIJWwARvxgge5wOa6v4peIbOPwTHo2rXWl6p4quZElnlsoUAswOSu8ZyeMdQTnPTGfEK9b+FPg3SobCTx14tkhj0S0YpBFOu5ZpOm4juAScADkj25b8QvjDrGvapPpPhu6az0dZDHE1oCklz2yW4IB7KMdec1D8YUntNN8Gadqcks2t2+mE3ksjZOGI2Kec5XDgkjnjr2840rTLrWtWtdMso99zdSrFGvuT39q7/4ga1aeHtOHw98ONiytWB1S4By15c8ZBP91SMY9RjtziH4YeKk0ebUp7BLdYoGuPs80yrO0S/ecR53YHfIFcfWp4c1+98L+ILTWtOKfarViyCRcqQVKkEehBI/GvZp7TTYfhhq/irRNGt9E8RXdmsksMdw0jR2skm0yIG/1e8BsY7Dg14LTo5HhlSWJ2SRCGV1OCpHQg9jXqnwx8TeKNc8ZWq6l4o1T+ytOR7+9Ml05XyoxnDc8gttBB7E1wPivXH8SeK9T1hgQLu4Z0UnJVM4UfgMCsep7KyudSvoLKzhaa5ncRxRoOWYnAFd/wCOJ7Xwn4dtvAWmXEc06P8AaNauIjlZLjtFn0T+fUAg15zXUeBLzwva68y+LbGS506eFoRJGxzbs3HmYHXAz9OoBIrr4/h14BluWvY/iRZDSVYMYpEC3O3P3QCQSccZC/h2rB+KfjO08Z+J4pdNjkj02xtxa23mdXAJJfHbOQPoB3rhq6LwfrGq+Ftfs9c07ThdSr5iRLLCzo524bGO4DA8HjivVINX1Lxl4R1rUPiLpFjbabFauthqUkHkzi4z8iR92HXoO2DnmvCaK+hrDQ7rwVJ4euJdQXSvDmjwC8vbtmAOo3Eq5ZEXqwxhOemDgZrwnXb6DU9f1G/tbf7Nb3NzJNHDn/VqzEhfwzWfXvM3hHUNb+Eeh6d4MvNOXSpI/tGrySXARnuMKSrnHG30z2HtXFW0vh/4cu11b31r4g8TKP8AR2gXfZWZ/v7jzI47YAA/CuBu7u4v7ya7u53nuJnLySyNlmY9STUNe+/Df4h+JNdvC98tvZ+FtE09jdJbQBY22xkKGZiSCeuFI+70614LK4eZ3VdoZiQuc49qZXvWs678NPHPhrRLW+8RXmhx6fCIxYRwMwU4A5IQ5xjg59eK5NfFfgrwQ4fwbpsuq6ntyuqaqOIGxj93GAOe+T+orzvUdRvNX1Ce/wBQuZLi6nYvJLIclif5fTtV3wvrr+GfE+na0kImNnMJDGTjcOhGe3BNeo+G/EPwqsvHP/CSmbWbWWQvIsF1AJIoJG6sCu4nGTjg4z7VyHib4hPqEN7p+kWaWdvdnF3eNK091eAf35WAIU4B2gAe3auGrX8LaVDrnivStLuZhDBd3UcUjk4wpYZwfXHA98V6n8Q9Xh8P2nie1e4tm1fXZorZbO3YMLGyg+VA+MgOwA+Xt14rxWiiiitnw34mvvCt5cXmmpbi7lt2gSeSPc8G7GXjOflfGRnngmsh3eWRpJHZ3YkszHJJPcmm0UUUV02l/EPxZomhro2ma1Pa2CszLHEqgqWznD43DqT161h3upX+ouHvr24umBJBnlZyMnJ6mqtFFFFFFFFbN14q1m80CHQpLtV0uF9620MMcSlsY3NsUFzx1bJrGooooooooooor//Z","image/png":"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","text/plain":["<PIL.Image.Image image mode=L size=280x28>"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["random_test_img_idxs = random.sample(list(range(len(test_dataset))), 10)\n","random_test_imgs = [test_dataset[i][0] for i in random_test_img_idxs]\n","\n","transforms.functional.to_pil_image(torch.cat(random_test_imgs, -1))"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"data":{"text/plain":["['<SOS> in this image , the number four is shown <EOS>',\n"," '<SOS> number seven is displayed here <EOS>',\n"," '<SOS> number five is displayed here <EOS>',\n"," '<SOS> we can see the number eight in this image <EOS>',\n"," '<SOS> number eight is displayed here <EOS>',\n"," '<SOS> here , you can see the number zero <EOS>',\n"," '<SOS> number nine is displayed here <EOS>',\n"," '<SOS> number zero is displayed here <EOS>',\n"," '<SOS> here , you can see the number six <EOS>',\n"," '<SOS> we can see the number eight in this image <EOS>']"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["with torch.no_grad():\n","    generated_captions = [model.caption_image(t_img.to(device)) for t_img in random_test_imgs]\n","\n","generated_captions = [' '.join(tokens) for tokens in generated_captions]\n","\n","generated_captions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
