{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from IPython.display import clear_output"],"metadata":{"id":"mUswXp0-tlNV","executionInfo":{"status":"ok","timestamp":1719692791836,"user_tz":-300,"elapsed":848,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# No need to run this on colab. These libraries come pre-installed on colab\n","# %pip install torch torchvision torchaudio"],"metadata":{"id":"DMHK_Wpytpr3","executionInfo":{"status":"ok","timestamp":1719692797584,"user_tz":-300,"elapsed":680,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Content:\n","\n","In this demo, we will take do some AI-based code generation, like the kind done my github co-pilot or codenium or other code completion services.\n","\n","The model we will use is codeLlama. CodeLlama models are basically llama-v2 models fine tuned for coding tasks. Code llama is available in different sizes and we'll use the 7B params model variant.\n","\n","\n","For this, we need to install the library and to download the model weights file. The file can be downloaded from huggingface [repo](https://huggingface.co/TheBloke/CodeLlama-7B-GGUF) of [TheBloke](https://huggingface.co/TheBloke). Credits to him for quantizing the model, saving it in different formats like GGML and GGUF and sharing with the community. He has a lot of other models on his channel that you can check out, including different versions of llama"],"metadata":{"id":"16xxZX0Ft4XL"}},{"cell_type":"markdown","source":["## Downloading model file"],"metadata":{"id":"2mnqKpa4vvrk"}},{"cell_type":"code","source":["!wget https://huggingface.co/TheBloke/CodeLlama-7B-GGUF/resolve/main/codellama-7b.Q5_K_M.gguf\n","\n","clear_output()"],"metadata":{"id":"UejyX_MntcGt","executionInfo":{"status":"ok","timestamp":1719692825473,"user_tz":-300,"elapsed":26811,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Installing llama-cpp-python\n","\n","installing supports different versions of hardware acceleration.\n","\n","We will go with Cuda. Checkout the [Github Repo](https://github.com/abetlen/llama-cpp-python) for more options"],"metadata":{"id":"wvuFeDu3wZDd"}},{"cell_type":"code","source":["!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python==0.2.74  # This takes a few mins when building wheel. Be patient."],"metadata":{"id":"qG7Mz0UuwCty","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719693936955,"user_tz":-300,"elapsed":1052302,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}},"outputId":"3446434f-4c2a-4a82-8b29-b007a9102e07"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-cpp-python\n","  Downloading llama_cpp_python-0.2.79.tar.gz (50.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.2)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n","Collecting diskcache>=5.6.1 (from llama-cpp-python)\n","  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n","Building wheels for collected packages: llama-cpp-python\n","  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.79-cp310-cp310-linux_x86_64.whl size=172348951 sha256=9a7230215712e5c9d21b89b26776d555c5e5a88ef19168afc8fbb1f332eba27a\n","  Stored in directory: /root/.cache/pip/wheels/bb/2e/11/8b10c6b698e6abc1289e9919e098ac4bcf6b16ebd46153e8ba\n","Successfully built llama-cpp-python\n","Installing collected packages: diskcache, llama-cpp-python\n","Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.79\n"]}]},{"cell_type":"markdown","source":["## Running Llama-v2"],"metadata":{"id":"k0F2JhjiyiiD"}},{"cell_type":"code","source":["import json\n","\n","from llama_cpp import Llama"],"metadata":{"id":"caVzdA9vxri4","executionInfo":{"status":"ok","timestamp":1719693947538,"user_tz":-300,"elapsed":685,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model = Llama(\n","    \"codellama-7b.Q5_K_M.gguf\",\n","    n_gpu_layers=-1, # To use GPU\n","    n_ctx=2048,\n",")\n","\n","clear_output()"],"metadata":{"id":"GTiK6FuFyqk6","executionInfo":{"status":"ok","timestamp":1719693980286,"user_tz":-300,"elapsed":2614,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Let's try a code generation example. How about a function to open an RGB image, convert it to greyscale and then save it."],"metadata":{"id":"j60Xyt0b49KW"}},{"cell_type":"code","source":["prompt = \"\"\"\n","from PIL import Image\n","\n","def convert_to_greyscale(input_path, output_path):\n","\"\"\""],"metadata":{"id":"ZM1D8ZG1ql8a","executionInfo":{"status":"ok","timestamp":1719693985937,"user_tz":-300,"elapsed":676,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["output = model.__call__(\n","    prompt,\n","    max_tokens=None,  # sets no length limit\n","    temperature=0.5,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KCUObzRh1wtc","executionInfo":{"status":"ok","timestamp":1719694054227,"user_tz":-300,"elapsed":64644,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}},"outputId":"e2a3dc2c-52a7-4cd9-919a-c8a1a99fa941"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","llama_print_timings:        load time =     406.14 ms\n","llama_print_timings:      sample time =    1051.62 ms /  2019 runs   (    0.52 ms per token,  1919.89 tokens per second)\n","llama_print_timings: prompt eval time =     405.59 ms /    29 tokens (   13.99 ms per token,    71.50 tokens per second)\n","llama_print_timings:        eval time =   57862.54 ms /  2018 runs   (   28.67 ms per token,    34.88 tokens per second)\n","llama_print_timings:       total time =   63874.75 ms /  2047 tokens\n"]}]},{"cell_type":"code","source":["output.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ty1NLAjk10pr","executionInfo":{"status":"ok","timestamp":1719694151582,"user_tz":-300,"elapsed":6,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}},"outputId":"46e6b2b2-d5da-43a6-9fc3-857335084a47"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['id', 'object', 'created', 'model', 'choices', 'usage'])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["print(output[\"choices\"][0]['text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YwZ68PIA2HHr","executionInfo":{"status":"ok","timestamp":1719694104126,"user_tz":-300,"elapsed":725,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}},"outputId":"a9c55e5f-6eb0-48a3-c642-abdb46e2f3af"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["    \"\"\"\n","    Converts a color image to greyscale.\n","\n","    Parameters:\n","        input_path (str): Path to the input image.\n","        output_path (str): Path to save the converted image.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    img = Image.open(input_path)\n","    img = img.convert('L')\n","    img.save(output_path)\n","\n","def convert_to_binary(input_path, output_path):\n","    \"\"\"\n","    Converts an image to a binary image by thresholding.\n","\n","    Parameters:\n","        input_path (str): Path to the input image.\n","        output_path (str): Path to save the converted image.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    img = Image.open(input_path)\n","    # Convert to greyscale and threshold\n","    img = img.convert('L')\n","    img = img.point(lambda x : 255 if x > 128 else 0, '1')\n","    img.save(output_path)\n","\n","def convert_to_negative(input_path, output_path):\n","    \"\"\"\n","    Converts an image to negative by inverting the pixels.\n","\n","    Parameters:\n","        input_path (str): Path to the input image.\n","        output_path (str): Path to save the converted image.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    img = Image.open(input_path)\n","    # Convert to greyscale and invert pixels\n","    img = img.convert('L')\n","    img = ImageOps.invert(img)\n","    img.save(output_path)\n","\n","def convert_to_sepia(input_path, output_path):\n","    \"\"\"\n","    Converts an image to sepia by modifying the red and green channels.\n","\n","    Parameters:\n","        input_path (str): Path to the input image.\n","        output_path (str): Path to save the converted image.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    img = Image.open(input_path)\n","    # Modify red and green channels for sepia effect\n","    img = img.convert('RGB')\n","    pixels = list(img.getdata())\n","    newPixels = []\n","    for pixel in pixels:\n","        r, g, b = pixel\n","        newR = int((0.393 * r) + (0.769 * g) + (0.189 * b))\n","        newG = int((0.349 * r) + (0.686 * g) + (0.168 * b))\n","        newB = int((0.272 * r) + (0.534 * g) + (0.131 * b))\n","        if newR > 255:\n","            newR = 255\n","        if newG > 255:\n","            newG = 255\n","        if newB > 255:\n","            newB = 255\n","        newPixels.append((newR, newG, newB))\n","    img.putdata(newPixels)\n","    img.save(output_path)\n","\n","def convert_to_edges(input_path, output_path):\n","    \"\"\"\n","    Converts an image to an edge image by blurring and then thresholding.\n","\n","    Parameters:\n","        input_path (str): Path to the input image.\n","        output_path (str): Path to save the converted image.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    img = Image.open(input_path)\n","    # Convert to greyscale and blur\n","    img = img.convert('L')\n","    img = img.filter(ImageFilter.BLUR)\n","    # Threshold the image\n","    img = img.point(lambda x : 255 if x > 128 else 0, '1')\n","    img.save(output_path)\n","\n","def convert_to_embossed(input_path, output_path):\n","    \"\"\"\n","    Converts an image to an embossed image by blurring and then applying a\n","    negative filter.\n","\n","    Parameters:\n","        input_path (str): Path to the input image.\n","        output_path (str): Path to save the converted image.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    img = Image.open(input_path)\n","    # Convert to greyscale and blur\n","    img = img.convert('L')\n","    img = img.filter(ImageFilter.BLUR)\n","    # Apply a negative filter\n","    img = ImageOps.invert(img)\n","    img.save(output_path)\n","\n","def convert_to_sharpened(input_path, output_path):\n","    \"\"\"\n","    Converts an image to a sharpened image by blurring and then applying a\n","    negative filter.\n","\n","    Parameters:\n","        input_path (str): Path to the input image.\n","        output_path (str): Path to save the converted image.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    img = Image.open(input_path)\n","    # Convert to greyscale and blur\n","    img = img.convert('L')\n","    img = img.filter(ImageFilter.BLUR)\n","    # Apply a negative filter\n","    img = ImageOps.invert(img)\n","    img.save(output_path)\n","\n","def convert_to_blurred(input_path, output_path):\n","    \"\"\"\n","    Converts an image to a blurred image by blurring it.\n","\n","    Parameters:\n","        input_path (str): Path to the input image.\n","        output_path (str): Path to save the converted image.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    img = Image.open(input_path)\n","    # Convert to greyscale and blur\n","    img = img.convert('L')\n","    img = img.filter(ImageFilter.BLUR)\n","    img.save(output_path)\n","\n","def convert_to_smoothed(input_path, output_path):\n","    \"\"\"\n","    Converts an image to a smoothed image by blurring it.\n","\n","    Parameters:\n","        input_path (str): Path to the input image.\n","        output_path (str): Path to save the converted image.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    img = Image.open(input_path)\n","    # Convert to greyscale and blur\n","    img = img.convert('L')\n","    img = img.filter(ImageFilter.BLUR)\n","    img.save(output_path)\n","\n","def convert_to_embossed_sepia(input_path, output_path):\n","    \"\"\"\n","    Converts an image to a sepia embossed image by blurring and then applying\n","    both filters in succession.\n","\n","    Parameters:\n","        input_path (str): Path to the input image.\n","        output_path (str): Path to save the converted image.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    img = Image.open(input_path)\n","    # Convert to greyscale and blur\n","    img = img.convert('L')\n","    img = img.filter(ImageFilter.BLUR)\n","    # Apply a negative filter first, then sepia effect\n","    img = ImageOps.invert(img)\n","    pixels = list(img.getdata())\n","    newPixels = []\n","    for pixel in pixels:\n","        r, g, b = pixel\n","        newR = int((0.393 * r) + (0.769 * g) + (0.189 * b))\n","        newG = int((0.349 * r) + (0.686 * g) + (0.168 * b))\n","        newB = int((0.272 * r) + (0.534 * g) + (0.131 * b))\n","        if newR > 255:\n","            newR = 255\n","        if newG > 255:\n","            newG = 255\n","        if newB > 255:\n","            newB = 255\n","        newPixels.append((newR, newG, newB))\n","    img.putdata(newPixels)\n","    img = ImageOps.invert(img)\n","    img.save(output_path)\n","\n","def convert_to_sharpened_sepia(input_path, output_path):\n","    \"\"\"\n","\n"]}]},{"cell_type":"markdown","source":["Let's try a translation example now. Something a little more complex.\n","\n","How about a deep learning example"],"metadata":{"id":"c-tQxdpO69wo"}},{"cell_type":"code","source":["prompt = \"\"\"\n","# Simple script to download MNIST, Create a pytorch classifier class, and training it for the MNIST.\n","\n","import torch\n","\"\"\""],"metadata":{"id":"Rda-Lcfa6z2H","executionInfo":{"status":"ok","timestamp":1719695019118,"user_tz":-300,"elapsed":688,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["output = model(prompt, max_tokens=None, temperature=0.1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FipmD9rb74j_","executionInfo":{"status":"ok","timestamp":1719695051475,"user_tz":-300,"elapsed":29907,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}},"outputId":"7043e71f-9da0-4863-987a-1e4a9422eca7"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":["Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =     406.14 ms\n","llama_print_timings:      sample time =     536.29 ms /  1009 runs   (    0.53 ms per token,  1881.44 tokens per second)\n","llama_print_timings: prompt eval time =     121.30 ms /    24 tokens (    5.05 ms per token,   197.86 tokens per second)\n","llama_print_timings:        eval time =   28394.03 ms /  1008 runs   (   28.17 ms per token,    35.50 tokens per second)\n","llama_print_timings:       total time =   30370.10 ms /  1032 tokens\n"]}]},{"cell_type":"code","source":["print(output[\"choices\"][0]['text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vC5iU1uv8UNG","executionInfo":{"status":"ok","timestamp":1719695083831,"user_tz":-300,"elapsed":677,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"}},"outputId":"10dd32af-67a6-42f8-d259-e79ba6f8ce4e"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["from torch import nn\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","# Download MNIST dataset\n","train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n","test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n","\n","# Define a classifier\n","class Classifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n","        self.pool1 = nn.MaxPool2d(kernel_size=2)\n","        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n","        self.pool2 = nn.MaxPool2d(kernel_size=2)\n","        self.fc1 = nn.Linear(in_features=7*7*64, out_features=1024)\n","        self.fc2 = nn.Linear(in_features=1024, out_features=10)\n","    \n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv1(x)))\n","        x = self.pool2(F.relu(self.conv2(x)))\n","        x = x.view(-1, 7*7*64)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Create a classifier\n","classifier = Classifier()\n","\n","# Define loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(classifier.parameters(), lr=0.01)\n","\n","# Train the model\n","for epoch in range(5):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.view(-1, 28*28).float()\n","        optimizer.zero_grad()\n","        outputs = classifier(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    print('Epoch: {}/{}.. '.format(epoch+1, 5), 'Loss: {:.6f}'.format(loss))\n","\n","# Test the model\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.view(-1, 28*28).float()\n","        outputs = classifier(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n","\n","# Save model\n","torch.save(classifier, 'mnist_model.pth')\n","\n","# Plot some examples\n","dataiter = iter(test_loader)\n","images, labels = dataiter.next()\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images))\n","# print labels\n","print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n","\n","# Predictions\n","outputs = classifier(images)\n","_, predicted = torch.max(outputs, 1)\n","\n","print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n","\n","plt.figure()\n","imshow(torchvision.utils.make_grid(images))\n","plt.title\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XKpEaQHHMN5B"},"execution_count":null,"outputs":[]}]}