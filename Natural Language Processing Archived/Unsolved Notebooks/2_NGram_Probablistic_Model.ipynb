{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711847386867,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"KWJQkUiwOhDk"},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711847389194,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"go_txTCnOllo"},"outputs":[],"source":["# %pip install nltk tqdm\n","\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"xNn4k_1tO8wJ"},"source":["# Content:\n","\n","In this demo, you will build an N-gram probabilistic based Language model\n","\n","Use NLTK library to download the dataset and handle our text.\n","\n","Make sure to show your model's working by generating and showing a few texts using the model"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1386,"status":"ok","timestamp":1711847453382,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"0XdTwtMLKd1H","outputId":"9b6eb18c-1708-4d1c-cf2b-25b357e0e5fe"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import random\n","\n","import nltk\n","from nltk.util import ngrams as build_ngrams\n","from nltk.tokenize import word_tokenize\n","from collections import defaultdict\n","from tqdm import tqdm\n","\n","nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{"id":"A44rzQ3RPkqX"},"source":["## Downloading the dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711847454689,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"_l14RpFVOSPm","outputId":"924ab151-d0a1-4355-fb48-c52b58fa3639"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Package movie_reviews is already up-to-date!\n"]}],"source":["# Download the IMDB dataset\n","nltk.download('movie_reviews')\n","from nltk.corpus import movie_reviews"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1711847528042,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"Gxv7nlqJ5Hzf"},"outputs":[],"source":["tokenized_data = movie_reviews.sents()  # sents is sentences (not full reviews as can be very long). They are alread tokenized."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1711847529566,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"jhVXSKpWVRc9"},"outputs":[],"source":["sos_token = '<SOS>'  # start of sentence token. Appending this at the start will make the selection of first token also probabilistic based according to corpus\n","eos_token = '<EOS>'  # to indicate a sentence has ended and we should stop generating"]},{"cell_type":"markdown","metadata":{"id":"DoyvrQ3cXBDW"},"source":["## Building the model\n","\n","Write the code for your language model and train it on the data.\n","\n","Make sure that you can pass the n-gram size parameter as an argument.\n","\n","Also make sure that when generating the text, you have the option to pass the initial part of the sentnece(and the model will complete the sentence) along with the model generating the entire text itself"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1711847530146,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"nMW8F-DPP2ph"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"7Ts62f2El5qa"},"source":["## Let's see the results\n","\n","1. Generate a few texts(atleast 5) from the very beginning using the model(model creates the whole text)\n","2. Generate a few texts(atleast 2) where you provide the starting part of the sentence and let the model complete it"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ixPQ286T_7Ab"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPomR91qptJvbKoObaaTTWQ","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
