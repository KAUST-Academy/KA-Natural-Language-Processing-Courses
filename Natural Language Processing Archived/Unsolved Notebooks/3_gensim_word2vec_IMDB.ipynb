{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":571,"status":"ok","timestamp":1712522054362,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"1Kyq7id3RFlx"},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9402,"status":"ok","timestamp":1712522562295,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"sIFHl7ibRLEt"},"outputs":[],"source":["# %pip install gensim nltk tqdm scikit-learn\n","\n","%pip install datasets\n","\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"L6qBaPbbRZI-"},"source":["# Content\n","\n","In this demo, you will train a word2vec(gensim implementation) model on custom data. We will use IMDB dataset as our training data"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":357,"status":"ok","timestamp":1712523481624,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"aTPmrcboRP1c"},"outputs":[],"source":["import nltk\n","from gensim.models import Word2Vec\n","from nltk.tokenize import word_tokenize\n","from tqdm import tqdm\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","from datasets import load_dataset\n","\n","\n","nltk.download('punkt')\n","\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"G1aPCG39TOd6"},"source":["## Preparing the data"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21352,"status":"ok","timestamp":1712522629642,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"DejqTT0YRDZy","outputId":"cf9f4e67-c268-4487-f301-a582223b3f64"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 25000/25000 [00:21<00:00, 1176.71it/s]\n"]}],"source":["train_data = load_dataset('imdb', split='train')['text']\n","train_data = train_data[:500]  # shorten the data because all 25k rows take too long to train"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10366,"status":"ok","timestamp":1712522724824,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"vgYVGGxnTTsn","outputId":"a427a80a-c0a5-4646-8353-8d51b4d65743"},"outputs":[{"name":"stderr","output_type":"stream","text":["Tokenizing data: 100%|██████████| 5000/5000 [00:10<00:00, 470.89it/s]\n"]}],"source":["tokenized_train_data = [word_tokenize(text.lower()) for text in tqdm(train_data, desc='Tokenizing data')]"]},{"cell_type":"markdown","metadata":{"id":"YKWZHhUiUBiw"},"source":["## Train the model\n","\n","Initialize the model and train it on the data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XiFtgK5xVoSY"},"source":["## Try the model\n","\n","1. Take a few words spread across some categories(for example you can take a few animals, a few movie genres etc)\n","2. use your model to generate vectors for each of these words\n","4. for each word's vector, calculate it's similarity with all the remaining word's vectors\n","3. for each word, show the most similar word in the remaining list. You can use cosine similarity to find similarity between vectors. higher cosine similarity = more similar. make sure to remove the original word from the list when calculating similarity as a word is always most similar to itself"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"GIEFNgNHbZik"},"source":["## Finidng similar words\n","\n","Take a few different words and use your model to find most similar words to it in the corpus. Show the results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jz8L7hohdC_r"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOvjuYqCmGIFU6bZw8Cc+PX","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
