{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":695,"status":"ok","timestamp":1719698635040,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"8kf0eYR_8Cc3"},"outputs":[],"source":["from IPython.display import clear_output"]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true,"executionInfo":{"elapsed":19937,"status":"ok","timestamp":1719698657196,"user":{"displayName":"Telha Bin Bilal","userId":"04147761314111353462"},"user_tz":-300},"id":"imCadh94-id0"},"outputs":[],"source":["%pip install accelerate\n","%pip install bitsandbytes\n","\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"cMcZGsPB89h8"},"source":["# Content\n","\n","In this notebook, we will use the multi-model model llava.\n","Llava can take image along with text as input and can answer questions or chat about the image.\n","\n","We'll use huggingface to download and infer the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wbaZbtUmIpCZ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMqVIO6uR1rIkvuYYcyR6xX","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
